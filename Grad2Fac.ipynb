{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0207a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_csv('taskdata.csv')\n",
    "FAC=np.asarray([data.FAC1_1, data.FAC2_1,data.FAC3_1,data.FAC4_1]).T\n",
    "GRAD=np.asarray([data.Gradient1, data.Gradient2,data.Gradient3]).T\n",
    "KeepIndex=~np.isnan(FAC[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Tasklabels,Taskindices=np.unique(data.Task_name,return_inverse=True)\n",
    "FAC_TaskCentres=np.zeros([10,4])\n",
    "for i in range(10):\n",
    "    FAC_TaskCentres[i,:]=FAC[Taskindices==i+1,:].mean(axis=0)\n",
    "\n",
    "Grad_TaskCentres=np.zeros([10,3])\n",
    "for i in range(10):\n",
    "\n",
    "    Grad_TaskCentres[i,:]=GRAD[np.ix_(Taskindices==(i+1),[0,1,2])].mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c3ca4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 0.5. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 0.1. Increasing the bound and calling fit again may find a better value.\n",
      "\n",
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 0.5. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 0.1. Increasing the bound and calling fit again may find a better value.\n",
      "\n",
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 0.5. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "c:\\Users\\Smallwood Lab\\anaconda3\\envs\\gpr\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 0.1. Increasing the bound and calling fit again may find a better value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit whole dataset\n",
    "\n",
    "\n",
    "\n",
    "fig_estimated_mean = make_subplots(rows=2, cols=2, subplot_titles=(\"Component 1\", \"Component 2\", \"Component 3\", \"Component 4\"),specs=[[{'type': 'surface'}, {'type': 'surface'}],[{'type': 'surface'}, {'type': 'surface'}]])\n",
    "\n",
    "fig_standard_deviation = make_subplots(rows=2,cols=2, subplot_titles=(\"Component 1\", \"Component 2\", \"Component 3\", \"Component 4\"),specs=[[{'type': 'surface'}, {'type': 'surface'}],[{'type': 'surface'}, {'type': 'surface'}]])\n",
    "\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(1,4,figsize=(16, 4), dpi=150)\n",
    "# fig2, axs2 = plt.subplots(1,4,figsize=(16, 4), dpi=150)\n",
    "\n",
    "count = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "\n",
    "        standardscaler=StandardScaler()\n",
    "        X=Grad_TaskCentres\n",
    "\n",
    "        y = standardscaler.fit_transform(FAC_TaskCentres[:,count].reshape(-1,1))    \n",
    "\n",
    "\n",
    "        kernel = 1.0 * Matern(length_scale=0.5, length_scale_bounds=(0.5, 1), nu=2.5) + WhiteKernel(noise_level_bounds=[0.001,0.1],noise_level=0.05)\n",
    "\n",
    "\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, random_state=3,normalize_y=False,alpha=0)\n",
    "        gpr.fit(X, y)\n",
    "\n",
    "\n",
    "        lim = 0.6\n",
    "        res = 50\n",
    "        lin = np.linspace(-lim, lim, res)\n",
    "\n",
    "        \n",
    "        x1, x2, x3 = np.meshgrid(lin, lin, lin)\n",
    "\n",
    "        xx = np.vstack((x1.flatten(), x2.flatten(), x3.flatten())).T\n",
    "\n",
    "        y_mean, y_sd = gpr.predict(xx, return_std=True)\n",
    "\n",
    "\n",
    "        fig_estimated_mean.add_trace(go.Volume(\n",
    "            x=pd.Series(x1.flatten(),name=\"Gradient 1\"),\n",
    "            y=pd.Series(x2.flatten(),name=\"Gradient 2\"),\n",
    "            z=pd.Series(x3.flatten(),name=\"Gradient 3\"),\n",
    "            value=y_mean,\n",
    "            hoverinfo='skip',\n",
    "            opacityscale=[[0, 0.8], [0.35, 0],[0.65, 0], [1, 0.8]],\n",
    "            surface_count=25,\n",
    "            showlegend=False,\n",
    "            #showscale=False,\n",
    "            \n",
    "            colorbar={\"tickmode\":\"array\",'tickvals': [min(y_mean),max(y_mean)],'ticktext': [\"Predicted low loading\",\"Predicted high loading\"]}\n",
    "\n",
    "            ),i+1,j+1)\n",
    "\n",
    "        fig_estimated_mean.add_trace(go.Scatter3d(\n",
    "            x=Grad_TaskCentres[:,0], \n",
    "            y=Grad_TaskCentres[:,1],\n",
    "            z=Grad_TaskCentres[:,2],\n",
    "            marker_color=FAC_TaskCentres[:,count],\n",
    "            text=Tasklabels,mode=\"markers+text\",\n",
    "            #marker_colorbar={\"tickmode\":\"array\",'tickvals': [0,1],'ticktext': [\"Low predicted loading\",\"High predicted loading\"]}\n",
    "            showlegend=False,\n",
    "            ),i+1,j+1)\n",
    "\n",
    "        #fig_estimated_mean.update_layout(coloraxis_colorbar={\"tickmode\":\"array\",'tickvals': [0,1],'ticktext': [\"Low predicted loading\",\"High predicted loading\"]})\n",
    "        \n",
    "        #fig_estimated_mean.update_coloraxes(colorbar=dict(tickmode=\"array\",tickvals=[-1,1],ticktext=[\"High predicted loading\",\"Low predicted loading\"])) \n",
    "    \n",
    "\n",
    "        fig_standard_deviation.add_trace(go.Volume(\n",
    "            x=pd.Series(x1.flatten(),name=\"Gradient 1\"),\n",
    "            y=pd.Series(x2.flatten(),name=\"Gradient 2\"),\n",
    "            z=pd.Series(x3.flatten(),name=\"Gradient 3\"),\n",
    "            value=y_sd,\n",
    "            hoverinfo='skip',\n",
    "            showlegend=False,\n",
    "            #showscale=False,\n",
    "            opacityscale=[[0, 0.8], [0.35, 0],[0.65, 0], [1, 0.8]],\n",
    "            colorbar={\"tickmode\":\"array\",'tickvals': [min(y_sd),max(y_sd)],'ticktext': [\"Low uncertainty in predicted loading\",\"High uncertainty in predicted loading\"]},\n",
    "            surface_count=25,\n",
    "            ),i+1,j+1)\n",
    "        count += 1\n",
    "        fig_estimated_mean.update(layout_coloraxis_showscale=False)\n",
    "        # axs[i].scatter(x1, x2, c=y_mean,cmap='bwr',alpha=0.5)\n",
    "\n",
    "        # axs[i].scatter(Grad_TaskCentres[:,0], Grad_TaskCentres[:, 1],s=25,marker='x',c=FAC_TaskCentres[:,i],cmap='bwr')\n",
    "\n",
    "        # for j in range(10):\n",
    "        #     axs[i].text(Grad_TaskCentres[j,0],Grad_TaskCentres[j,1],  Tasklabels[j+1], size=8, zorder=1,color='k') \n",
    "\n",
    "        # axs2[i].scatter(x1, x2, c=y_sd,cmap='seismic')\n",
    "    #fig_estimated_mean.update_coloraxes(colorbar=dict(showticklabels=False,tickmode=\"array\",tickvals=[1,-1],ticktext=[\"High predicted loading\",\"Low predicted loading\"])) \n",
    " \n",
    "fig_estimated_mean.write_html(\"estimated_mean.html\")\n",
    "fig_standard_deviation.write_html(\"standard_deviation.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do in 3 gradient dimensions\n",
    "Tasklabels,Taskindices=np.unique(data.Task_name,return_inverse=True)\n",
    "FAC_TaskCentres=np.zeros([10,4])\n",
    "for i in range(10):\n",
    "    FAC_TaskCentres[i,:]=FAC[Taskindices==i+1,:].mean(axis=0)\n",
    "\n",
    "Grad_TaskCentres=np.zeros([10,3])\n",
    "for i in range(10):\n",
    "    #Grad_TaskCentres[i,:]=GRAD[Taskindices==i+1,(0,2)].mean(axis=0)\n",
    "    Grad_TaskCentres[i,:]=GRAD[np.ix_(Taskindices==(i+1),[0,1,2])].mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Assess out of sample prediction with 3d gradient\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(8, 8), dpi=150)\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "numFac=3\n",
    "\n",
    "X=Grad_TaskCentres\n",
    "standardscaler=StandardScaler()\n",
    "avg_acc_score=np.zeros([numFac])\n",
    "pred_Fac=np.zeros([10,numFac])\n",
    "real_Fac=np.zeros([10,numFac])\n",
    "\n",
    "for i in range(numFac):\n",
    "    acc_score = []\n",
    "    y = standardscaler.fit_transform(FAC_TaskCentres[:,i].reshape(-1,1))    \n",
    "\n",
    "    for train_index , test_index in kf.split(X):\n",
    "\n",
    "        X_train , X_test = X[train_index,:],X[test_index,:]\n",
    "        y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "        kernel = 1.0 * Matern(length_scale=0.5, length_scale_bounds=(0.5, 1), nu=2.5)+ WhiteKernel(noise_level_bounds=[0.001,0.5],noise_level=0.05)\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, random_state=3,normalize_y=False,alpha=0.0)\n",
    "\n",
    "        gpr.fit(X_train, y_train)\n",
    "        pred_values = gpr.predict(X_test)\n",
    "        pred_Fac[test_index,i]=pred_values\n",
    "        real_Fac[test_index,i]=y_test\n",
    "        acc=np.abs(pred_values-y_test.T).sum()\n",
    "        acc_score.append(acc)\n",
    "        \n",
    "    avg_acc_score[i] = np.median(acc_score)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "ax.scatter(pred_Fac[:,0],pred_Fac[:,1],pred_Fac[:,2],c='k',marker='+')\n",
    "ax.scatter(real_Fac[:,0],real_Fac[:,1],real_Fac[:,2],c='k',marker='o')\n",
    "\n",
    "for i in range(10):\n",
    "    ax.plot([pred_Fac[i,0],real_Fac[i,0]],[pred_Fac[i,1],real_Fac[i,1]],[pred_Fac[i,2],real_Fac[i,2]],c='k',marker='')\n",
    "    ax.text(real_Fac[i,0],real_Fac[i,1],real_Fac[i,2],Tasklabels[i+1],c='k')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca662c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(np.power(pred_Fac-real_Fac,2).mean(axis=1),0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6aaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Tasklabels,Taskindices=np.unique(data.Task_name,return_inverse=True)\n",
    "FAC_TaskCentres=np.zeros([10,4])\n",
    "for i in range(10):\n",
    "    FAC_TaskCentres[i,:]=FAC[Taskindices==i+1,:].mean(axis=0)\n",
    "\n",
    "Grad_TaskCentres=np.zeros([10,3])\n",
    "for i in range(10):\n",
    "    #Grad_TaskCentres[i,:]=GRAD[Taskindices==i+1,(0,2)].mean(axis=0)\n",
    "    Grad_TaskCentres[i,:]=GRAD[Taskindices==i+1,:].mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "k = 4\n",
    "kernel = 1.0 * Matern(length_scale=0.5, length_scale_bounds=(0.5, 1), nu=2.5) #+WhiteKernel(noise_level_bounds=[0.001,0.5],noise_level=0.1)\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=None,normalize_y=True,alpha=0.1)\n",
    "X=Grad_TaskCentres\n",
    "#X=FAC_TaskCentres\n",
    "standardscaler=StandardScaler()\n",
    "#y = standardscaler.fit_transform(FAC_TaskCentres[:,0].reshape(-1,1))    \n",
    "y = FAC_TaskCentres[:,0]\n",
    "#y = standardscaler.fit_transform(Grad_TaskCentres[:,2].reshape(-1,1))    \n",
    "\n",
    "\n",
    "\n",
    "#score_gradfac, perm_scores_gradfac, pvalue_gradfac = permutation_test_score(gpr, X, y, scoring=\"neg_root_mean_squared_error\", cv=kf, n_permutations=100)\n",
    "score_gradfac, perm_scores_gradfac, pvalue_gradfac = permutation_test_score(gpr, X, y, scoring=\"neg_mean_absolute_error\", cv=kf, n_permutations=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_gradfac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_gradfac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6a264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('gpr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bce8f376a3dc2c197604a06e7e05438ccd7ca7fbe84c8386480d864d293a56c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
